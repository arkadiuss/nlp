{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f25b0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import FAISSDocumentStore,ElasticsearchDocumentStore\n",
    "from haystack.nodes import DensePassageRetriever\n",
    "from nlp_common.acts_reader import ActsReader\n",
    "import regex\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3db74086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da000b3c8a1446fb6d3144aca234458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61927100ac404eb48aa8671c9871b13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6eb3dcbcad42d98fe87d5dbb054661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/886k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0516172ae829428195e27630c02af729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/543k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5215853fc391405cb80402183149424e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/129 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='enelpol/czywiesz-context', vocab_size=50000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "AutoTokenizer.from_pretrained(\"enelpol/czywiesz-question\")\n",
    "AutoTokenizer.from_pretrained(\"enelpol/czywiesz-context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49fb29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_store = ElasticsearchDocumentStore()\n",
    "faiss_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "350052b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'HerbertTokenizerFast'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_995/2215782099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m faiss_retriever = DensePassageRetriever(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdocument_store\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfaiss_store\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mquery_embedding_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"enelpol/czywiesz-question\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpassage_embedding_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"enelpol/czywiesz-context\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/studies/nlp2/9_neural_search/haystack/haystack/nodes/retriever/dense.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, document_store, query_embedding_model, passage_embedding_model, model_version, max_seq_len_query, max_seq_len_passage, top_k, use_gpu, batch_size, embed_title, use_fast_tokenizers, infer_tokenizer_classes, similarity_function, global_loss_buffer_size, progress_bar, devices, use_auth_token)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Init & Load Encoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         self.query_tokenizer = Tokenizer.load(pretrained_model_name_or_path=query_embedding_model,\n\u001b[0m\u001b[1;32m    152\u001b[0m                                               \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                               \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/studies/nlp2/9_neural_search/haystack/haystack/modeling/model/tokenization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, pretrained_model_name_or_path, revision, tokenizer_class, use_fast, use_auth_token, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"DPRQuestionEncoderTokenizer\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDPRQuestionEncoderTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDPRQuestionEncoderTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/studies/nlp2/9_neural_search/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         return cls._from_pretrained(\n\u001b[0m\u001b[1;32m   1745\u001b[0m             \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/studies/nlp2/9_neural_search/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1768\u001b[0m         \u001b[0mhas_tokenizer_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizer_file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfrom_slow\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_tokenizer_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslow_tokenizer_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m             slow_tokenizer = (cls.slow_tokenizer_class)._from_pretrained(\n\u001b[0m\u001b[1;32m   1771\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/studies/nlp2/9_neural_search/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1877\u001b[0m         \u001b[0;31m# Instantiate tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1879\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1880\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m             raise OSError(\n",
      "\u001b[0;32m~/studies/nlp2/9_neural_search/venv/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case, do_basic_tokenize, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             raise ValueError(\n\u001b[1;32m    195\u001b[0m                 \u001b[0;34mf\"Can't find a vocabulary file at path '{vocab_file}'. To load the vocabulary from a Google pretrained \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
     ]
    }
   ],
   "source": [
    "faiss_retriever = DensePassageRetriever(\n",
    "    document_store=faiss_store,\n",
    "    query_embedding_model=\"enelpol/czywiesz-question\",\n",
    "    passage_embedding_model=\"enelpol/czywiesz-context\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a118366",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "216fed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = ActsReader(\"../ustawy\")\n",
    "bills = [ (name, text) for name, _, text in reader.all_acts() ]\n",
    "\n",
    "def split_articles_single_bill(bill):\n",
    "    r = regex.compile(r\"Art\\.[\\s|\\n]\\d+\")\n",
    "    art_cleanup_re = regex.compile(r'\\n*|\\s*|\\t*')\n",
    "    new_line_re = regex.compile(r'\\n+|\\s+|\\t+')\n",
    "    \n",
    "    expected_num = 1\n",
    "    pos = []\n",
    "    for m in r.finditer(bill):\n",
    "        aid = art_cleanup_re.sub('', m.group(0))\n",
    "        if aid[4:] == str(expected_num):\n",
    "            expected_num += 1\n",
    "            pos.append((aid, m.start(0)))\n",
    "\n",
    "    if len(pos) < 1:\n",
    "        return []\n",
    "    \n",
    "    arts = []\n",
    "    for i in range(1, len(pos)):\n",
    "        sub = bill[pos[i-1][1]:pos[i][1]]\n",
    "        sub = new_line_re.sub(' ', sub)\n",
    "        arts.append((pos[i-1][0],sub))\n",
    "    \n",
    "    sub = bill[pos[-1][1]:]\n",
    "    sub = new_line_re.sub(' ', sub)\n",
    "    arts.append((pos[-1][0],sub))\n",
    "         \n",
    "    return arts\n",
    "    \n",
    "def split_articles(bills):\n",
    "    docs = []\n",
    "    for name, bill in bills:\n",
    "        arts = split_articles_single_bill(bill)\n",
    "        for art,content in arts:\n",
    "            docs.append({\n",
    "                \"content\": content,\n",
    "                \"meta\": { \"name\": f\"{name}:{art}\" }\n",
    "            })\n",
    "    return docs\n",
    "        \n",
    "articles = split_articles(bills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ccb81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_store.write_documents(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss_store.write_documents(articles)\n",
    "# faiss_store.update_embeddings(faiss_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1291224",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53591735",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Art. 268. Właściwe organy Państwowej Straży Pożarnej w razie wystąpienia awarii przemysłowej są obowiązane do:  1) podjęcia działań operacyjno-ratowniczych we współpracy z prowadzącym  zakład,  2) zebrania informacji niezbędnych do dokonania analizy awarii i  sformułowania zaleceń dla prowadzącego zakład,  3) sprawdzenia, czy prowadzący zakład podjął wszystkie konieczne środki  zaradcze,  4) opracowania zaleceń dotyczących zastosowania w przyszłości określonych  środków zapobiegawczych,  5) sprawdzenia, czy prowadzący zakład wdrożył zalecenia właściwego organu  Państwowej Straży Pożarnej.  ',\n",
       " 'meta': {'name': '2001_627.txt:Art.268'}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    { \"question\": \"Kto jest ubezpieczonymi na podstawie przepisów prawa?\", \"passage_id\": \"2001_906.txt:Art.2\" },\n",
    "    { \"question\": \"Na czyj wniosek Rada Ministrów ustala cenę minimalną ziemniaków?\", \"passage_id\": \"2001_83.txt:Art.11\" },\n",
    "    { \"question\": \"Do czego zobowiązane są organy Państwowej Straży Pożarnej w razie wystąpienia awarii przemysłowej?\", \n",
    "      \"passage_id\": \"2001_627.txt:Art.268\" },\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
