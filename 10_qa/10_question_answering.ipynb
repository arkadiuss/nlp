{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0f12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer, AutoTokenizer\n",
    "from datasets import Dataset,DatasetDict\n",
    "from transformers import default_data_collator\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059f8a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dkleczek/bert-base-polish-cased-v1 were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dkleczek/bert-base-polish-cased-v1 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "qa_cased_bert_model = AutoModelForQuestionAnswering.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dkleczek/bert-base-polish-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a039479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_squad_format(dataset):\n",
    "    res = {\n",
    "        \"id\": [],\n",
    "        \"question\": [],\n",
    "        \"answers\": [],\n",
    "        \"context\": [],\n",
    "        \"title\": []\n",
    "    }\n",
    "    for act in dataset[\"data\"]:\n",
    "        title = act[\"title\"]\n",
    "        for para in act[\"paragraphs\"]:\n",
    "            ctx = para[\"context\"]\n",
    "            for q in para[\"qas\"]:\n",
    "                q[\"context\"] = ctx\n",
    "                q[\"title\"] = title\n",
    "                answers = {\"answer_start\": [], \"text\": []}\n",
    "                for an in q[\"answers\"]:\n",
    "                    answers[\"answer_start\"].append(an[\"answer_start\"])\n",
    "                    answers[\"text\"].append(an[\"text\"])\n",
    "                q[\"answers\"] = answers\n",
    "                for c in [\"id\", \"question\", \"answers\", \"context\", \"title\"]:\n",
    "                    res[c].append(q[c])\n",
    "    return Dataset.from_dict(res)\n",
    "    \n",
    "def read_dataset():\n",
    "    dataset = {}\n",
    "    for t in [\"train\", \"dev\", \"test\"]:\n",
    "        with open(f\"lqad-pl-1/lqad-pl-{t}.json\") as f:\n",
    "            dataset[t] = to_squad_format(json.loads(f.read()))\n",
    "    return DatasetDict(dataset)\n",
    "\n",
    "dataset = read_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b13112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2007_adw_1',\n",
       " 'question': 'Wybrany do Sejmu może być obywatel polski mający prawo wybierania, który: ',\n",
       " 'answers': {'answer_start': [115],\n",
       "  'text': ['najpóźniej w dniu wyborów kończy 21 lat']},\n",
       " 'context': ' Rozdział IV SEJM I SENAT Art . 99 § 1 . Wybrany do Sejmu może być obywatel polski mający prawo wybierania , który najpóźniej w dniu wyborów kończy 21 lat . § 2 . Wybrany do Senatu może być obywatel polski mający prawo wybierania , który najpóźniej w dniu wyborów kończy 30 lat . § 3 . Wybraną do Sejmu lub do Senatu nie może być osoba skazana prawomocnym wyrokiem na karę pozbawienia wolności za przestępstwo umyślne ścigane z oskarżenia publicznego .',\n",
       " 'title': 'Konstytucja Rzeczypospolitej Polskiej z dnia 2 kwietnia 1997 r. uchwalona przez Zgromadzenie Narodowe w dniu 2 kwietnia 1997 r., przyjęta przez Naród w referendum konstytucyjnym w dniu 25 maja 1997 r., podpisana przez Prezydenta Rzeczypospolitej Polskiej w dniu 16 lipca 1997 r'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4926e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://huggingface.co/docs/transformers/custom_datasets#load-squad-dataset\n",
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc254d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9d23fb2de043989d0b61cdf97a0a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f99fc263464ce2a14966e7884f8ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163f70b58c614dd99226d8ad83d594fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75469b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(model):\n",
    "    data_collator = default_data_collator\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"dev\"],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9bbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_herbert_model_tuned = finetune(qa_herbert_model)\n",
    "# qa_herbert_model_tuned.save_pretrained(\"herbert-base-cased-legal-qa-tuned\")\n",
    "\n",
    "qa_herbert_model_tuned = AutoModelForQuestionAnswering.from_pretrained(\"herbert-base-cased-legal-qa-tuned\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c6aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_cased_bert_model_tuned = finetune(qa_cased_bert_model)\n",
    "# qa_cased_bert_model_tuned.save_pretrained(\"bert-base-polish-cased-v1-legal-qa-tuned\")\n",
    "\n",
    "qa_cased_bert_model_tuned_t = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-polish-cased-v1-legal-qa-tuned\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75ce9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, test_y):\n",
    "    y = predictions\n",
    "    print(predictions, test_y)\n",
    "    accuracy = accuracy_score(y, test_y)\n",
    "    precision = precision_score(y, test_y)\n",
    "    recall = recall_score(y, test_y)\n",
    "    f1 = f1_score(y, test_y)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} \n",
    "\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    return evaluate(pred, labels)\n",
    "\n",
    "def evaluate_transformers(model):\n",
    "    trainer = Trainer(model=model,\n",
    "                      tokenizer=tokenizer)\n",
    "\n",
    "    return trainer.predict(tokenized_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ac7a48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 463\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 02:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = evaluate_transformers(qa_herbert_model_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "907e9988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([[-7.4329634, -7.368832 , -6.617597 , ..., -7.5947294, -7.752664 ,\n",
       "        -7.778024 ],\n",
       "       [-7.4106345, -7.181142 , -6.629648 , ..., -7.7880297, -7.7957063,\n",
       "        -7.798563 ],\n",
       "       [-7.404494 , -7.2709823, -6.6942706, ..., -7.7840433, -7.820159 ,\n",
       "        -7.8105807],\n",
       "       ...,\n",
       "       [-7.421554 , -7.0127587, -6.7157335, ..., -7.8349066, -7.8224626,\n",
       "        -7.821253 ],\n",
       "       [-7.3961077, -7.0576873, -6.702667 , ..., -7.8544455, -7.837531 ,\n",
       "        -7.824364 ],\n",
       "       [-7.6010027, -7.3299994, -6.6196427, ..., -7.9354043, -7.9293175,\n",
       "        -7.9480586]], dtype=float32), array([[-7.1161537, -7.0751667, -6.731268 , ..., -7.2099695, -7.2679033,\n",
       "        -7.239803 ],\n",
       "       [-7.2239404, -7.1294746, -6.9316454, ..., -7.3927536, -7.386673 ,\n",
       "        -7.373506 ],\n",
       "       [-7.234407 , -7.2176886, -6.839652 , ..., -7.4629517, -7.448105 ,\n",
       "        -7.4722033],\n",
       "       ...,\n",
       "       [-7.2303357, -7.15343  , -6.945491 , ..., -7.3965178, -7.3968616,\n",
       "        -7.4006944],\n",
       "       [-7.153534 , -7.1294394, -6.9135695, ..., -7.3596144, -7.394079 ,\n",
       "        -7.3313875],\n",
       "       [-7.175151 , -7.125645 , -6.8073797, ..., -7.3356967, -7.3630877,\n",
       "        -7.34319  ]], dtype=float32)), label_ids=(array([ 41, 129,  69,  46,  67,  54,  47,  49,  74, 159,  42,  59,  41,\n",
       "        73,  84,  57,  51,  49,  64,  59,  50, 159,  63,  76,  74, 230,\n",
       "        75,  42,  52,  88,  86,  46,  94,  55,  70,  70,  54,  53,  63,\n",
       "        30,  63,  56,  71,  55,  56,  71,  52,  37,  70,  57,  68,  51,\n",
       "        48,  51,  59,  44, 104,  61,  34,  51,  36,  56,  87,  40,  78,\n",
       "        36,  84,  44,  57,  68,  42,  50, 107,  79,  93,  64,  58, 140,\n",
       "       141,  56,  70,  40,  53,  63,  45,  64,  85,  41,  64,  32,  40,\n",
       "        40,  28,  57,  70,  30,  32,  62,  56,  46, 100,  29,  38,  78,\n",
       "        62, 109,  35, 109,  60, 114,  64,  65,  31,  39,  34,  50,  51,\n",
       "        51,  22,  81,  67,  35,  58,  45,  36,  88,  25,  31,  31,  55,\n",
       "        30,  32,  33,  38,  30,  28,  22,  35,  61,  47,  25,  48,  62,\n",
       "        24,  55,  73, 117,  68,  65,  40,  45, 217,  43,  30,  45,  49,\n",
       "        50,  61,  44,  80,  63,  30,  91,  52,  51,  44,  71,  55,  47,\n",
       "        84,  64,  52,  68,  54,  58,  51,  72,  53,  44,  45,  45,  96,\n",
       "        67, 130, 126, 176,  84, 125, 120, 211, 109,  63, 131,  50,  49,\n",
       "        27,  32,  73,  36,  57,  46,  65,  62,  43,  50,  37,  46,  47,\n",
       "        35,  46,  68,  67,  76,  56,  69,  37,  51,  33,  46,  32,  59,\n",
       "        25,  43,  68,  37, 248,  47,  53,  39,  60,  58,  59,  53,  68,\n",
       "        67,  59,  65,  50,  84,  65,  65, 118,  59,  48, 114,  70, 128,\n",
       "        52,  56, 116, 116,  43,  65,  55,  76,  51,  44,  76,  37,  64,\n",
       "        32,  96,  40,  34,  51,  50,  89,  32,  44,  41,  44,  38,  48,\n",
       "        44, 101,  41,  55,  51,  69,  50,  60,  50,  92,  38,  41,  37,\n",
       "        44,  43,  45,  33, 108,  30,  46,  48,  52,  36,  81,  64,  67,\n",
       "        46,  76,  63,  40,  47,  35,  44,  24,  24,  50,  28,  26,  34,\n",
       "        32,  36,  32,  20,  88,  25,  33,  37,  48,  39,  40,  24,  45,\n",
       "        37,  37,  90, 124, 132, 105,  94, 139, 151, 120, 106,  91, 124,\n",
       "       123, 132, 111, 109, 101,  92, 124, 128,  77,  78,  94, 124,  78,\n",
       "        81,  72,  82, 139, 135,  87,  94,  80,  71,  70,  69, 111,  42,\n",
       "        31,  65,  63,  49,  63,  45,  23,  19,  46,  34,  53, 110,  57,\n",
       "        31,  68,  33,  24,  56,  80,  33,  59,  24, 110, 109,  51, 158,\n",
       "        51,  46,  42, 100, 101,  38,  92,  90,  81, 155, 157,  37,  51,\n",
       "        54,  80,  71,  48,  43,  80,  47,  33,  73,  86,  56,  70,   8,\n",
       "        27,  43,  31,  44,  51,  33,  37, 115,  56,  50,  31,  83,  49,\n",
       "        40,  33,  46,  51,  38,  44,  71,  71,  67,  54,  33,  71,  80,\n",
       "        62,  34,  77,  57,  61,  59,  57,  49, 104,  55,  47,  58,  61,\n",
       "        74,  64,  41,  70,  63,  45,  41,  86]), array([ 45, 131,  73,  47,  82,  56,  50,  55,  79, 161,  88,  67,  44,\n",
       "        78,  86,  65,  59,  52,  68,  67,  57, 161,  64,  78,  84, 237,\n",
       "        79,  45,  66,  89,  93,  52, 111,  56,  75,  88,  77,  59,  75,\n",
       "        31,  71,  57,  72,  56,  69,  89,  59,  38,  71,  63,  72,  69,\n",
       "        52,  51,  59,  48, 105,  73,  48,  66,  41,  64,  88,  52,  93,\n",
       "        53, 131,  72,  64,  76,  59,  50, 124,  94, 140,  80,  75, 163,\n",
       "       147,  63,  74,  53,  68,  83,  45,  99,  92,  42,  91,  36,  52,\n",
       "        52,  34,  63,  83,  32,  37,  62,  62,  60, 103,  31,  47,  78,\n",
       "        70, 145,  40, 111,  62, 116,  64,  72,  32,  40,  51,  57,  57,\n",
       "        64,  27,  90,  68,  37,  62,  46,  36,  88,  26,  32,  33,  56,\n",
       "        32,  37,  34,  47,  30,  38,  23,  35,  62,  50,  26,  50,  72,\n",
       "        25,  57,  76, 117,  71,  68,  50,  50, 221,  46,  31,  45,  50,\n",
       "        51,  68,  45,  84,  69,  31,  95,  53,  54,  63,  83,  58,  48,\n",
       "        94,  64,  53,  70,  73,  65,  52,  74,  69,  47,  47,  54,  96,\n",
       "        72, 144, 140, 187,  99, 139, 129, 231, 123,  78, 142,  63,  49,\n",
       "        32,  41,  77,  37,  66,  50,  72,  63,  47,  55,  41,  49,  57,\n",
       "        50,  48,  80,  78,  78,  62,  77,  40,  57,  36,  46,  41,  68,\n",
       "        26,  44,  75,  60, 260,  62,  61,  42,  80,  59,  68,  57,  79,\n",
       "        68,  63,  73,  54,  89,  66,  73, 119,  63,  49, 115,  77, 141,\n",
       "        56,  60, 117, 117,  47,  73,  70,  85,  51,  45,  85,  38,  79,\n",
       "        37,  98,  40,  38,  51,  51,  95,  35,  50,  42,  47,  43,  53,\n",
       "        45, 129,  45,  72,  56,  73,  57,  90,  67,  99,  39,  57,  40,\n",
       "        47,  51,  53,  38, 112,  37,  53,  53,  57,  37,  98,  71,  73,\n",
       "        53,  77,  72,  45,  47,  38,  57,  34,  35,  51,  39,  26,  35,\n",
       "        32,  38,  32,  30,  90,  26,  37,  38,  50,  41,  45,  27,  45,\n",
       "        37,  39,  92, 141, 132, 106,  99, 143, 157, 123, 108,  96, 125,\n",
       "       124, 134, 112, 118, 112,  95, 127, 156,  88,  96, 110, 127,  79,\n",
       "        83,  91,  88, 139, 145, 126, 115,  82,  77,  71,  82, 112,  43,\n",
       "        33,  66,  76,  50,  67,  47,  25,  19,  48,  35,  53, 111,  59,\n",
       "        33,  69,  38,  25,  60,  91,  42,  75,  27, 122, 115,  67, 161,\n",
       "        53,  48,  54, 109, 110,  41,  92,  92,  83, 160, 160,  38,  58,\n",
       "        57,  85,  73,  50,  44,  84,  49,  34,  77, 107,  59,  80,   9,\n",
       "        28,  44,  34,  49,  52,  33,  38, 116,  61,  51,  35,  86,  51,\n",
       "        41,  43,  48,  51,  40,  44,  71,  71,  69,  56,  33,  73,  82,\n",
       "        69,  39, 110,  71,  61,  60,  60,  55, 109,  58,  54,  60,  61,\n",
       "        79,  67,  61,  83,  66,  54,  42,  86])), metrics={'test_loss': 1.2144825458526611, 'test_runtime': 168.642, 'test_samples_per_second': 2.745, 'test_steps_per_second': 0.344})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb3b9cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'end_positions', 'input_ids', 'start_positions', 'token_type_ids'],\n",
       "    num_rows: 463\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48211a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
